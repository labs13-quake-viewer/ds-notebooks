{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Animated Map with `folium`\n",
    "\n",
    "https://nbviewer.jupyter.org/github/python-visualization/folium/blob/master/examples/Plugins.ipynb#Timestamped-GeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "from folium import plugins\n",
    "import requests\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('https://earthquake.usgs.gov/earthquakes/'\n",
    "#                  'feed/v1.0/summary/2.5_day.csv')\n",
    "df = pd.read_csv('https://earthquake.usgs.gov/earthquakes/'\n",
    "                 'feed/v1.0/summary/2.5_month.csv')\n",
    "\n",
    "# df['time'] = pd.to_datetime(df['time'], utc=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get faults\n",
    "r = requests.get('https://raw.githubusercontent.com/'\n",
    "                 'fraxen/tectonicplates/master/GeoJSON/'\n",
    "                 'PB2002_boundaries.json')\n",
    "\n",
    "fault_features = r.json()['features']\n",
    "\n",
    "# for feature in fault_features:\n",
    "#     feature['properties']['color'] = 'red'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fault_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/PB2002_boundaries.json\", \"r\") as read_file:\n",
    "    fault_feats = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"features\": {\"features\": [{\"geometry\": {\"coordinates\": [[-0.4379, -54.8518], [-0.038826, -54.6772], [0.443182, -54.4512], [0.964534, -54.8322], [1.69481, -54.399], [2.35975, -54.0374], [3.02542, -53.6507], [3.36894, -53.8341], [3.95638, -54.1267], [4.41458, -54.4303], [4.82661, -54.1616], [5.08372, -54.3093], [5.49469, -54.5429], [6.18373, -54.1145], [6.6254, -53.8142], [7.23729, -54.1012], [7.77235, -54.396]], \"type\": \"LineString\"}, \"properties\": {\"LAYER\": \"plate boundary\", \"Name\": \"AF-AN\", \"PlateA\": \"AF\", \"PlateB\": \"AN\", \"Source\": \"Mueller et al. [1987]\", \"Type\": \"\"}, \"type\": "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    'type': 'FeatureCollection',\n",
    "    'features': fault_features,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    {\n",
    "        'type': 'Feature',\n",
    "        'geometry': {\n",
    "            'type': 'Point',\n",
    "            'coordinates': [r['longitude'], r['latitude']],\n",
    "        },\n",
    "        'properties': {\n",
    "            'time': r['time'][0:-1],\n",
    "            'popup': (\n",
    "                f\"<strong>Time:</strong> {r['time']}<br>\"\n",
    "                f\"<strong>Place:</strong> {r['place']}<br>\"\n",
    "                f\"<strong>Magnitude:</strong> {r['mag']} {r['magType']}<br>\"\n",
    "                f\"<strong>Depth:</strong> {r['depth']}<br>\"\n",
    "            ),\n",
    "            'icon': 'circle',\n",
    "            'iconstyle': {\n",
    "                'fillOpacity': 0.5,\n",
    "                'stroke': 0,\n",
    "                'radius': r['mag'] * 2.5\n",
    "            },\n",
    "        }\n",
    "    } for i, r in df.iterrows()\n",
    "]\n",
    "\n",
    "m = folium.Map(\n",
    "#     location=()\n",
    "    tiles='CartoDBpositron',\n",
    "#     zoom_start=1,\n",
    "#     no_wrap=True,\n",
    "    min_zoom=1.5,\n",
    "    max_zoom=5,\n",
    "    world_copy_jump=True,\n",
    ")\n",
    "\n",
    "# add faults\n",
    "folium.GeoJson(\n",
    "    {\n",
    "        'type': 'FeatureCollection',\n",
    "        'features': fault_features,\n",
    "    },\n",
    "    style_function = lambda x: {\n",
    "        'color': 'red',\n",
    "        'weight': 0.5,\n",
    "    }\n",
    ").add_to(m)\n",
    "\n",
    "plugins.TimestampedGeoJson(\n",
    "    {\n",
    "        'type': 'FeatureCollection',\n",
    "        'features': features\n",
    "    },\n",
    "    period='PT6H', # six hour\n",
    "    time_slider_drag_update=True,\n",
    "    duration='PT12H',\n",
    "    date_options='YYYY-MM-DD HH UTC'\n",
    ").add_to(m)\n",
    "\n",
    "folium.plugins.Fullscreen(\n",
    "    position='topright',\n",
    "    force_separate_button=True,\n",
    ").add_to(m)\n",
    "\n",
    "# m.save('earthquakes.html')\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import IFrame\n",
    "# IFrame('earthquakes_2.5_day.html', width='100%', height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulling Data from USGS\n",
    "\n",
    "https://earthquake.usgs.gov/fdsnws/event/1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "payload = {\n",
    "    'format': 'csv', \n",
    "#     'starttime': None,  # default last 30 days\n",
    "#     'endtime': '2019-06-03',  # default now\n",
    "    'minmagnitude': 0,  # default null\n",
    "    'limit': None,  # default null, returns 404 over 20,000\n",
    "}\n",
    "url = 'https://earthquake.usgs.gov/fdsnws/event/1/query'\n",
    "r = requests.get(url, params=payload)\n",
    "\n",
    "r.url\n",
    "\n",
    "df = pd.read_csv(StringIO(r.text))\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Damage Data\n",
    "from https://www.ngdc.noaa.gov/nndc/struts/form?t=101650&s=1&d=1\n",
    "\n",
    "> The Significant Earthquake Database contains information on destructive earthquakes from 2150 B.C. to the present that meet at least one of the following criteria: \n",
    "> * Moderate damage (approximately $1 million or more)\n",
    "> * 10 or more deaths\n",
    "> * Magnitude 7.5 or greater\n",
    "> * Modified Mercalli Intensity X or greater\n",
    "> * the earthquake generated a tsunami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmg = pd.read_csv('https://www.ngdc.noaa.gov/nndc/struts/results?'\n",
    "                  'type_0=Exact&query_0=$ID&t=101650&s=13&d=189&dfn=signif.txt',\n",
    "                  sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmg.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contour Plot\n",
    "\n",
    "One nice way to display likelihoods of earthquake, once we have them\n",
    "\n",
    "https://www.tjansson.dk/2018/10/contour-map-in-folium/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import folium\n",
    "import branca\n",
    "from folium import plugins\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "import geojsoncontour\n",
    "import scipy as sp\n",
    "import scipy.ndimage\n",
    " \n",
    "# Setup\n",
    "temp_mean = 12\n",
    "temp_std  = 2\n",
    "debug     = False\n",
    " \n",
    "# Setup colormap\n",
    "colors = ['#d7191c',  '#fdae61',  '#ffffbf',  '#abdda4',  '#2b83ba']\n",
    "vmin   = temp_mean - 2 * temp_std\n",
    "vmax   = temp_mean + 2 * temp_std\n",
    "levels = len(colors)\n",
    "cm     = branca.colormap.LinearColormap(colors, vmin=vmin, vmax=vmax).to_step(levels)\n",
    " \n",
    "# Create a dataframe with fake data\n",
    "df = pd.DataFrame({\n",
    "    'longitude':   np.random.normal(11.84,     0.15,     1000),\n",
    "    'latitude':    np.random.normal(55.55,     0.15,     1000),\n",
    "    'temperature': np.random.normal(temp_mean, temp_std, 1000)})\n",
    " \n",
    "# The original data\n",
    "x_orig = np.asarray(df.longitude.tolist())\n",
    "y_orig = np.asarray(df.latitude.tolist())\n",
    "z_orig = np.asarray(df.temperature.tolist())\n",
    " \n",
    "# Make a grid\n",
    "x_arr          = np.linspace(np.min(x_orig), np.max(x_orig), 500)\n",
    "y_arr          = np.linspace(np.min(y_orig), np.max(y_orig), 500)\n",
    "x_mesh, y_mesh = np.meshgrid(x_arr, y_arr)\n",
    " \n",
    "# Grid the values\n",
    "z_mesh = griddata((x_orig, y_orig), z_orig, (x_mesh, y_mesh), method='linear')\n",
    " \n",
    "# Gaussian filter the grid to make it smoother\n",
    "sigma = [5, 5]\n",
    "z_mesh = sp.ndimage.filters.gaussian_filter(z_mesh, sigma, mode='constant')\n",
    " \n",
    "# Create the contour\n",
    "contourf = plt.contourf(x_mesh, y_mesh, z_mesh, levels, alpha=0.5, colors=colors, linestyles='None', vmin=vmin, vmax=vmax)\n",
    " \n",
    "# Convert matplotlib contourf to geojson\n",
    "geojson = geojsoncontour.contourf_to_geojson(\n",
    "    contourf=contourf,\n",
    "    min_angle_deg=3.0,\n",
    "    ndigits=5,\n",
    "    stroke_width=1,\n",
    "    fill_opacity=0.5)\n",
    " \n",
    "# Set up the folium plot\n",
    "geomap = folium.Map([df.latitude.mean(), df.longitude.mean()], zoom_start=10, tiles=\"cartodbpositron\")\n",
    " \n",
    "# Plot the contour plot on folium\n",
    "folium.GeoJson(\n",
    "    geojson,\n",
    "    style_function=lambda x: {\n",
    "        'color':     x['properties']['stroke'],\n",
    "        'weight':    x['properties']['stroke-width'],\n",
    "        'fillColor': x['properties']['fill'],\n",
    "        'opacity':   0.6,\n",
    "    }).add_to(geomap)\n",
    " \n",
    "# Add the colormap to the folium map\n",
    "cm.caption = 'Temperature'\n",
    "geomap.add_child(cm)\n",
    " \n",
    "# Fullscreen mode\n",
    "plugins.Fullscreen(position='topright', force_separate_button=True).add_to(geomap)\n",
    " \n",
    "# Plot the data\n",
    "# geomap.save(f'data/folium_contour_temperature_map.html'\n",
    "geomap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions and Next Steps from Research\n",
    "\n",
    "* Download ~20 years of data\n",
    "* Group the world into regions - group by seismic properties? or a grid? do these seismic region groupings already exist?\n",
    "* for each region, determine how complete USGS datasets are based on Gutenberg–Richter law and compute the cutoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteratively Download USGS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import parse\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "def dl_quake_data(start_date, end_date, page_limt=10000):\n",
    "    start_date = parse(start_date).isoformat()\n",
    "    end_date = parse(end_date).isoformat()\n",
    "    payload = {\n",
    "        'format': 'csv',\n",
    "        'starttime': start_date,\n",
    "        'endtime': end_date,\n",
    "        'minmagnitude': 2,\n",
    "        'limit': page_limt,\n",
    "        'orderby': 'time-asc',\n",
    "    }\n",
    "    url = 'https://earthquake.usgs.gov/fdsnws/event/1/query'\n",
    "    r = requests.get(url, params=payload)\n",
    "    \n",
    "    if r.status_code != 200:\n",
    "        print('Error', r.status_code, r.url)\n",
    "        return False\n",
    "    \n",
    "    df = pd.read_csv(StringIO(r.text))\n",
    "    \n",
    "    dt_min = df['time'].iloc[0]\n",
    "    dt_max = df['time'].iloc[-1]\n",
    "    \n",
    "    fn = (f'{parse(dt_min).strftime(\"%Y-%m-%d\")}_'\n",
    "          f'{parse(dt_max).strftime(\"%Y-%m-%d\")}')\n",
    "    df.to_csv(f'data/{fn}.csv', index=False)\n",
    "    \n",
    "    print(fn)\n",
    "    \n",
    "    if len(df) == page_limt:\n",
    "         dl_quake_data(start_date=dt_max,\n",
    "                       end_date=end_date)\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# done '1999-01-01' to '2019-01-01'\n",
    "# dl_quake_data('1999-01-01', '2009-01-01', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "dfs = []\n",
    "for csv in Path('data').iterdir():\n",
    "    dfs.append(pd.read_csv(csv))\n",
    "    \n",
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.mag.hist(bins=int((df.mag.max() - df.mag.min()) * 10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "df['updated'] = pd.to_datetime(df['updated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(df['updated'] - df['time']).dt.days.hist(bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(df['time'].dt.year)['id'].count().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Earth Grid\n",
    "https://en.wikipedia.org/wiki/Geographic_coordinate_system#3D_Cartesian_coordinates\n",
    "\n",
    "**Potential Improvements:** \n",
    "\n",
    "* Define these regions algorithmically (like sklearn.clusters.DBSCAN, [clusterpy](https://github.com/clusterpy/), [Moran'sI](https://en.wikipedia.org/wiki/Moran's_I)) based on earthquake characteristics in the regions\n",
    "* [Use extant domain research](https://www.researchgate.net/publication/260702383_A_detailed_seismic_zonation_model_for_shallow_earthquakes_in_the_broader_Aegean_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roughly equidistant points on (cartesian) sphere\n",
    "#https://stackoverflow.com/a/44164075/11208892\n",
    "from numpy import pi, cos, sin, arccos, arange, arctan2, arcsin\n",
    "import mpl_toolkits.mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_pts = 3000\n",
    "indices = arange(0, num_pts, dtype=float) + 0.5\n",
    "\n",
    "phi = arccos(1 - 2*indices/num_pts)\n",
    "theta = pi * (1 + 5**0.5) * indices\n",
    "\n",
    "x, y, z = cos(theta) * sin(phi), sin(theta) * sin(phi), cos(phi);\n",
    "\n",
    "plt.figure().add_subplot(111, projection='3d').scatter(x, y, z);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to lat/lon, ignoring that the earth is not a sphere\n",
    "# https://stackoverflow.com/questions/1185408/converting-from-longitude-latitude-to-cartesian-coordinates\n",
    "lats = (360 * arcsin(z / 1)) / (2 * pi)\n",
    "lons = (360 * arctan2(y, x)) / (2 * pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot it\n",
    "import folium\n",
    "\n",
    "m = folium.Map(tiles='CartoDBpositron')\n",
    "\n",
    "for lat, lon in zip(lats, lons):                                \n",
    "    folium.CircleMarker([lat, lon], radius=1).add_to(m)\n",
    "\n",
    "m.save('equidistant_pts.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
